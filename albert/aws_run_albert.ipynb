{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "# the code below assumes that you configure boto3 with your AWS account\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html\n",
    "ec2 = boto3.resource('ec2')\n",
    "client = boto3.client('ec2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'demo-run'\n",
    "# ^-- must be unique per experiment\n",
    "\n",
    "coordinator_type = \"c5n.xlarge\"\n",
    "dht_port = 31337\n",
    "worker_type = \"g4dn.xlarge\"\n",
    "\n",
    "num_workers = 64  # adjust per your limits\n",
    "# note: you will be able to add more workers after the fact\n",
    "\n",
    "worker_cpus = 2\n",
    "root_disk_name = \"/dev/xvda\"\n",
    "disk_size_gib = 125\n",
    "\n",
    "aws_key_name = <YOUR AWS KEY NAME>\n",
    "image_id = \"ami-0db67995cd75f5a9f\"\n",
    "subnet = \"subnet-18f5b654\"\n",
    "security_group = \"sg-a75591d4\"\n",
    "\n",
    "repo_path = \"https://github.com/icml2021-submit/moshpit-sgd\"\n",
    "data_path = <URL TO YOUR REPLICA OF PREPROCESSED BOOKCORPUS>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the experiment name is unique.\n",
    "# disable this if you want to add more instances to an existing experiment\n",
    "existing_instances = ec2.instances.filter(Filters=[\n",
    "    {'Name': 'instance-state-name', 'Values': ['running']},\n",
    "    {'Name': 'tag:experiment', 'Values': [experiment_name]},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if list(existing_instances):\n",
    "    print(f\"Already running {experiment_name}: {list(existing_instances)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to remove all instances and spot requests, run this:\n",
    "existing_instances.terminate()\n",
    "requests_to_shutdown = []\n",
    "for request in client.describe_spot_instance_requests()['SpotInstanceRequests']:\n",
    "    if request['State'] == 'active' and any(\n",
    "        tag['Key'] == 'experiment' and tag['Value'] == experiment_name\n",
    "        for tag in request['Tags']):\n",
    "        requests_to_shutdown.append(request['SpotInstanceRequestId'])\n",
    "if requests_to_shutdown:\n",
    "    client.cancel_spot_instance_requests(\n",
    "        SpotInstanceRequestIds=requests_to_shutdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: run coordinator\n",
    "\n",
    "Coordinator is an instance that welcomes new peers into a decentralized training run. If coordinator is down, new peers can still join by initializing with one of the existing peers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinator_script = f'''#!/bin/bash -ex\n",
    "exec > >(tee /var/log/user-command.log|logger -t user-data -s 2>/dev/console) 2>&1\n",
    "\n",
    "\n",
    "# NOTE: docker run must be called without --it as there is no tty\n",
    "# check machine's /var/log/user-command.log for details\n",
    "\n",
    "docker run --name trainer_run --ipc=host --net=host anonymoussubmit/moshpit-sgd bash -c \"\"\"\n",
    "set -euxo pipefail\n",
    "\n",
    "git clone {repo_path} moshpit-sgd\n",
    "cd moshpit-sgd\n",
    "pip install -r requirements.txt\n",
    "pip install -e .\n",
    "\n",
    "\n",
    "cd albert\n",
    "pip install whatsmyip\n",
    "python run_first_peer.py --listen_on [::]:{dht_port}\n",
    "\n",
    "\"\"\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinator, = ec2.create_instances(\n",
    "    ImageId=image_id, InstanceType=coordinator_type,\n",
    "    MinCount=1, MaxCount=1,\n",
    "    SecurityGroupIds=[security_group], SubnetId=subnet,\n",
    "    KeyName=aws_key_name, UserData=coordinator_script,\n",
    "    TagSpecifications=[{'ResourceType': 'instance', 'Tags': [\n",
    "        {'Key':'experiment', 'Value': experiment_name},\n",
    "        {'Key':'role', 'Value': 'first_peer'}\n",
    "    ]}]\n",
    ")\n",
    "coordinator.wait_until_running()\n",
    "coordinator, = list(ec2.instances.filter(InstanceIds=[coordinator.id]))\n",
    "coordinator_endpoint = f\"{coordinator.public_ip_address}:{dht_port}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coordinator.public_ip_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import src\n",
    "\n",
    "probe = await src.DHTNode.create(listen=False)\n",
    "for i in range(20):\n",
    "    ping_response = await probe.protocol.call_ping(coordinator_endpoint)\n",
    "    if ping_response is not None:\n",
    "        print(\"Coordinator is now accessible to workers!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Coordinator is not accessible yet, will retry in 30s...\")\n",
    "        time.sleep(30)\n",
    "else:\n",
    "    print(\"Coordinator failed to launch for some reason.\")\n",
    "    print(\"Check /var/log/user-command.log at ec2-user@{coordinator_endpoint}\")\n",
    "    \n",
    "# this should normally take 7-12 retries depending on the will of Bezos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: run workers\n",
    "\n",
    "Workers are preemptible GPU instances that run compute gradients and perform Moshpit averaging. In this example, each worker is a single tesla T4 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_script = f'''#!/bin/bash -ex\n",
    "exec > >(tee /var/log/user-command.log|logger -t user-data -s 2>/dev/console) 2>&1\n",
    "\n",
    "set -euxo pipefail\n",
    "cd ~\n",
    "\n",
    "docker run --name new_run --gpus all --ipc=host --net=host anonymoussubmit/moshpit-sgd bash -c \"\"\"\n",
    "\n",
    "wget {data_path}\n",
    "mkdir -p ~/data\n",
    "tar xvfz archive.tar.gz -C ~/data\n",
    "\n",
    "git clone {repo_path} moshpit-sgd\n",
    "cd moshpit-sgd\n",
    "pip install -r requirements.txt\n",
    "pip install -e .\n",
    "\n",
    "cd albert\n",
    "ln -s ~/data ./data\n",
    "\n",
    "python run_trainer.py \\\n",
    "  --output_dir ./outputs --overwrite_output_dir \\\n",
    "  --logging_dir ./logs --logging_first_step --logging_steps 100 \\\n",
    "  --initial_peers {coordinator_endpoint} --seed 0\n",
    "\n",
    "\"\"\"\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2.create_instances(\n",
    "    ImageId=image_id, InstanceType=worker_type,\n",
    "    MinCount=num_workers, MaxCount=num_workers,\n",
    "    UserData=worker_script,\n",
    "    SecurityGroupIds=[security_group], SubnetId=subnet,\n",
    "    KeyName=aws_key_name,\n",
    "    BlockDeviceMappings=[{\"DeviceName\": root_disk_name, \"Ebs\" : { \"VolumeSize\" : disk_size_gib }}],\n",
    "    InstanceMarketOptions={\n",
    "        \"MarketType\": \"spot\",\n",
    "        \"SpotOptions\": {\n",
    "            \"SpotInstanceType\": \"persistent\",\n",
    "            \"InstanceInterruptionBehavior\": \"stop\"\n",
    "        }\n",
    "    },\n",
    "    TagSpecifications=[{'ResourceType': 'instance', 'Tags': [\n",
    "        {'Key':'experiment', 'Value': experiment_name},\n",
    "        {'Key':'role', 'Value': 'gpu_worker'}\n",
    "    ]}, {'ResourceType': 'spot-instances-request', 'Tags': [\n",
    "        {'Key':'experiment', 'Value': experiment_name},\n",
    "        {'Key':'role', 'Value': 'gpu_worker'}\n",
    "    ]}],\n",
    "    CpuOptions={\n",
    "          'CoreCount': worker_cpus,\n",
    "          'ThreadsPerCore': 2\n",
    "      },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for instance in list(ec2.instances.all()):\n",
    "    print(instance, instance.public_ip_address, instance.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the system progress, connect to any running trainer instance via ssh and `tail -f /var/log/user-command.log`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
